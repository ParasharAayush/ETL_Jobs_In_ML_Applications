{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Jobs in Machine Learning Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aayus\\AppData\\Local\\Temp\\ipykernel_20180\\1610716012.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
      "C:\\Users\\aayus\\AppData\\Local\\Temp\\ipykernel_20180\\1610716012.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'Age' with the median age\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing values in 'Embarked' with the most common embarkation point\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop the 'Cabin' column due to a high number of missing values\n",
    "data.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract titles from names\n",
    "data['Title'] = data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "# Create a family size feature\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize or scale numerical features and encode categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age      Fare  FamilySize  Sex_female  Sex_male  Embarked_C  \\\n",
      "0 -0.565736 -0.502445    0.059160         0.0       1.0         0.0   \n",
      "1  0.663861  0.786845    0.059160         1.0       0.0         1.0   \n",
      "2 -0.258337 -0.488854   -0.560975         1.0       0.0         0.0   \n",
      "3  0.433312  0.420730    0.059160         1.0       0.0         0.0   \n",
      "4  0.433312 -0.486337   -0.560975         0.0       1.0         0.0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  Title_Capt  Title_Col  ...  Title_Miss  Title_Mlle  \\\n",
      "0         0.0         1.0         0.0        0.0  ...         0.0         0.0   \n",
      "1         0.0         0.0         0.0        0.0  ...         0.0         0.0   \n",
      "2         0.0         1.0         0.0        0.0  ...         1.0         0.0   \n",
      "3         0.0         1.0         0.0        0.0  ...         0.0         0.0   \n",
      "4         0.0         1.0         0.0        0.0  ...         0.0         0.0   \n",
      "\n",
      "   Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \\\n",
      "0        0.0       1.0        0.0       0.0        0.0        0.0   \n",
      "1        0.0       0.0        1.0       0.0        0.0        0.0   \n",
      "2        0.0       0.0        0.0       0.0        0.0        0.0   \n",
      "3        0.0       0.0        1.0       0.0        0.0        0.0   \n",
      "4        0.0       1.0        0.0       0.0        0.0        0.0   \n",
      "\n",
      "   Title_the Countess  Survived  \n",
      "0                 0.0         0  \n",
      "1                 0.0         1  \n",
      "2                 0.0         1  \n",
      "3                 0.0         1  \n",
      "4                 0.0         0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Select numerical and categorical columns\n",
    "numerical_cols = ['Age', 'Fare', 'FamilySize']\n",
    "categorical_cols = ['Sex', 'Embarked', 'Title']\n",
    "\n",
    "# Include 'Survived' in the original DataFrame for transformation\n",
    "data = data[['Survived'] + numerical_cols + categorical_cols]\n",
    "\n",
    "# Define the transformers\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the transformations\n",
    "data_transformed = preprocessor.fit_transform(data.drop(columns=['Survived']))\n",
    "\n",
    "# Get the column names after transformation\n",
    "transformed_columns = numerical_cols + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Convert the transformed data back to a DataFrame for convenience\n",
    "data_transformed_df = pd.DataFrame(data_transformed.toarray(), columns=transformed_columns)\n",
    "\n",
    "# Add the 'Survived' column back to the transformed DataFrame\n",
    "data_transformed_df['Survived'] = data['Survived'].values\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(data_transformed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the clean and transformed data in a relational database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an SQLite database engine\n",
    "engine = create_engine('sqlite:///titanic.db')\n",
    "\n",
    "# Save the transformed DataFrame to a table named 'titanic_transformed'\n",
    "data_transformed_df.to_sql('titanic_transformed', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age      Fare  FamilySize  Sex_female  Sex_male  Embarked_C  \\\n",
      "0 -0.565736 -0.502445    0.059160         0.0       1.0         0.0   \n",
      "1  0.663861  0.786845    0.059160         1.0       0.0         1.0   \n",
      "2 -0.258337 -0.488854   -0.560975         1.0       0.0         0.0   \n",
      "3  0.433312  0.420730    0.059160         1.0       0.0         0.0   \n",
      "4  0.433312 -0.486337   -0.560975         0.0       1.0         0.0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  Title_Capt  Title_Col  ...  Title_Miss  Title_Mlle  \\\n",
      "0         0.0         1.0         0.0        0.0  ...         0.0         0.0   \n",
      "1         0.0         0.0         0.0        0.0  ...         0.0         0.0   \n",
      "2         0.0         1.0         0.0        0.0  ...         1.0         0.0   \n",
      "3         0.0         1.0         0.0        0.0  ...         0.0         0.0   \n",
      "4         0.0         1.0         0.0        0.0  ...         0.0         0.0   \n",
      "\n",
      "   Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \\\n",
      "0        0.0       1.0        0.0       0.0        0.0        0.0   \n",
      "1        0.0       0.0        1.0       0.0        0.0        0.0   \n",
      "2        0.0       0.0        0.0       0.0        0.0        0.0   \n",
      "3        0.0       0.0        1.0       0.0        0.0        0.0   \n",
      "4        0.0       1.0        0.0       0.0        0.0        0.0   \n",
      "\n",
      "   Title_the Countess  Survived  \n",
      "0                 0.0         0  \n",
      "1                 0.0         1  \n",
      "2                 0.0         1  \n",
      "3                 0.0         1  \n",
      "4                 0.0         0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to load data from the database\n",
    "def load_data_from_db(engine):\n",
    "    query = \"SELECT * FROM titanic_transformed\"\n",
    "    data_from_db = pd.read_sql(query, engine)\n",
    "    return data_from_db\n",
    "\n",
    "# Load the data\n",
    "data_loaded = load_data_from_db(engine)\n",
    "print(data_loaded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration with ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the features and target variable\n",
    "X = data_loaded.drop(columns=['Survived'])\n",
    "y = data_loaded['Survived']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
